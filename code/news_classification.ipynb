{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from spacy.lang.en import English\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = English().tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BoW Representations for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1340aba787de4637a95ab27ef3289fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../20news-bydate/20news-bydate-train/\"\n",
    "\n",
    "bbow = dict()\n",
    "cbow = dict()\n",
    "vocab = set()\n",
    "\n",
    "for cls in tqdm(os.listdir(data_dir)):\n",
    "    for doc in os.listdir(os.path.join(data_dir, cls)):\n",
    "        docid = \"/\".join([cls, doc])\n",
    "        tokens = tokenizer(open(os.path.join(data_dir, cls, doc)).read())\n",
    "        \n",
    "        doc_bbow = dict()\n",
    "        doc_cbow = dict()\n",
    "        for token in tokens:\n",
    "            tok = token.text.lower() # considering token text directily. Lemma can also be taken.\n",
    "            if tok.isalnum(): # only consider alphanumeric tokens\n",
    "                vocab.add(tok)\n",
    "                if tok not in doc_bbow:\n",
    "                    doc_bbow[tok] = 1\n",
    "                doc_cbow[tok] = doc_cbow.get(tok, 0) + 1\n",
    "        bbow[docid] = doc_bbow\n",
    "        cbow[docid] = doc_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e967ee4ae84360bf5c628b71e6711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"../20news-bydate/20news-bydate-test/\"\n",
    "test_bbow = dict()\n",
    "test_cbow = dict()\n",
    "\n",
    "classes =  os.listdir(test_dir)\n",
    "for cls in tqdm(classes):\n",
    "    for doc in os.listdir(os.path.join(test_dir, cls)):\n",
    "        \n",
    "        docid = \"/\".join([cls, doc])\n",
    "        tokens = tokenizer(open(os.path.join(test_dir, cls, doc)).read())\n",
    "        \n",
    "        doc_bbow = dict()\n",
    "        doc_cbow = dict()\n",
    "        \n",
    "        for token in tokens:\n",
    "            tok = token.text.lower()\n",
    "            if tok.isalnum():\n",
    "                if tok not in doc_bbow:\n",
    "                    doc_bbow[tok] = 1\n",
    "                doc_cbow[tok] = doc_cbow.get(tok, 0) + 1\n",
    "                \n",
    "        test_bbow[docid] = doc_bbow\n",
    "        test_cbow[docid] = doc_cbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching the BoW representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bbow.json', 'w') as f:\n",
    "    json.dump(bbow, f)\n",
    "with open('../data/cbow.json', 'w') as f:\n",
    "    json.dump(cbow, f)\n",
    "\n",
    "with open('../data/test_bbow.json', 'w') as f:\n",
    "    json.dump(test_bbow, f)\n",
    "with open('../data/test_cbow.json', 'w') as f:\n",
    "    json.dump(test_cbow, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Naive Bayes Classifier for News Classification (with both Multinomial and Poisson models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesNewsClassifier():\n",
    "    def __init__(self, model='multinomial', alpha=0.8, k=0.1):\n",
    "        \"\"\"Initializes the chosen type of Naive Bayes Classifier with given hyperparameters. \n",
    "\n",
    "        Args:\n",
    "            model (str, optional): Choose from ['poisson', 'multinomial']. Defaults to 'multinomial'.\n",
    "            alpha (float, optional): Trade-off weight for length normalization factor (only pertinent to poisson model). Defaults to 0.8.\n",
    "            k (float, optional): Laplace smoothing parameter. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        assert model in ['poisson', 'multinomial']\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.model = model        \n",
    "        \n",
    "    def _estimate_likelihoods_poisson(self, bow, classes, vocab, data_dir):\n",
    "        \"\"\"\n",
    "        Calculates values proportional to the marginal probability of each additional occurence of a\n",
    "        particular word in a particular class document. Assumes word counts are drawn from poisson distribution.\n",
    "        The poisson parameter estimation scales for document length to account for length variation among\n",
    "        articles belonging to the same class.\n",
    "        \"\"\"\n",
    "        topic_counts = {y: len(os.listdir(os.path.join(data_dir, y))) for y in classes}\n",
    "        \n",
    "        dlen = dict()\n",
    "        tlen = dict()\n",
    "        \n",
    "        for y in classes:\n",
    "            dlen[y] = dict()\n",
    "            for doc in os.listdir(os.path.join(data_dir, y)):\n",
    "                docid = \"/\".join([y, doc])\n",
    "                dlen[y][docid] = np.sum(list(bow[docid].values()))\n",
    "            tlen[y] = np.sum(list(dlen[y].values()))\n",
    "        \n",
    "        lambdas = {y: {v: 0 for v in vocab} for y in classes}\n",
    "        for y in tqdm(classes):            \n",
    "            for doc in tqdm(os.listdir(os.path.join(data_dir, y)), leave=False):\n",
    "                docid = \"/\".join([y, doc])\n",
    "                dlj = dlen[y][docid]\n",
    "                gdc = self.alpha*(1/topic_counts[y]) + (1 - self.alpha)*dlj/tlen[y]\n",
    "                normed_weight = gdc / (dlj + self.k * len(vocab))\n",
    "                for v in vocab:\n",
    "                    lambdas[y][v] += normed_weight * (bow[docid].get(v, 0) + self.k)\n",
    "                    \n",
    "        self.word_likelihoods = {y: dict() for y in classes}\n",
    "        \n",
    "        for y in classes:\n",
    "            for v in vocab:\n",
    "                self.word_likelihoods[y][v] = np.log(lambdas[y][v]) - lambdas[y][v]        \n",
    "        \n",
    "    \n",
    "    def _estimate_likelihoods_multinomial(self, bow, classes, vocab):\n",
    "        \"\"\"\n",
    "        Estimates likelihood of a particular word belonging to a document of a particular class.\n",
    "        Assumes words are drawn from a multinomial distribution.\n",
    "        \"\"\"\n",
    "        smoothed_counts = {y: {v: self.k for v in vocab} for y in classes}\n",
    "        for y in classes:\n",
    "            for doc in os.listdir(os.path.join(data_dir, y)):\n",
    "                docid = \"/\".join([y, doc])\n",
    "                for v, cnt in bow[docid].items():\n",
    "                    smoothed_counts[y][v] += cnt\n",
    "                    \n",
    "        self.word_likelihoods = {y: dict() for y in classes}\n",
    "        \n",
    "        for y in tqdm(classes):\n",
    "            den = np.log(np.sum(list(smoothed_counts[y].values())))\n",
    "            for v in vocab:\n",
    "                self.word_likelihoods[y][v] = np.log(smoothed_counts[y][v]) - den\n",
    "        \n",
    "        \n",
    "    def train(self, bow, vocab, classes, data_dir):\n",
    "        \"\"\"Fits the Naive Bayes model to training data by estimating distribution parameters.\"\"\"\n",
    "\n",
    "        print('Training Beginning ...')\n",
    "        self.classes =  classes        \n",
    "        \n",
    "        print('    Estimating class-wise likelihoods of words...')      \n",
    "        if self.model == 'multinomial': self._estimate_likelihoods_multinomial(bow, classes, vocab)\n",
    "        elif self.model == 'poisson': self._estimate_likelihoods_poisson(bow, classes, vocab, data_dir)\n",
    "        print('    Class-wise word likelihood estimation complete!\\n')\n",
    "        \n",
    "        print('    Estimating class priors ...')\n",
    "        self.priors = {y: len(os.listdir(os.path.join(data_dir, y))) for y in classes}\n",
    "        total = np.sum(list(self.priors.values()))\n",
    "        for y in classes:\n",
    "            self.priors[y] = np.log(self.priors[y]/total)\n",
    "        print('    Class prior estimation complete!\\n')\n",
    "        print('Training Complete!\\n')\n",
    "        \n",
    "        print(f'\\nAccuracy on train data: {100*self._accuracy_on_bowlist(bow)}%\\n')\n",
    "        \n",
    "    def predict(self, doc_bow):\n",
    "        \"\"\"Function to predict class of a particular document/news article.\"\"\"\n",
    "        posteriors = {y: self.priors[y] for y in self.classes}        \n",
    "        for v in doc_bow:\n",
    "            for y in self.classes:\n",
    "                posteriors[y] += doc_bow[v]*self.word_likelihoods[y].get(v, 0)\n",
    "        \n",
    "        return list(posteriors.keys())[np.argmax(list(posteriors.values()))]\n",
    "    \n",
    "    def _accuracy_on_bowlist(self, bow_list):\n",
    "        \"\"\"Returns prediction accuracy over a set of documents.\"\"\"\n",
    "        total_cnt, correct_cnt = 0, 0\n",
    "        for doc, doc_bow in bow_list.items():\n",
    "            total_cnt += 1\n",
    "            cls = doc.split('/')[0]\n",
    "            pred = self.predict(doc_bow)\n",
    "            if pred == cls: correct_cnt += 1\n",
    "        return np.round(correct_cnt/total_cnt, 4)\n",
    "    \n",
    "    def test(self, bow):\n",
    "        \"\"\"Member function for allowing users to evaluate on test datasets.\"\"\"\n",
    "        print('Evaluating test data ...')\n",
    "        print(f'\\nEvaluation complete!\\nAccuracy on test data: {100*self._accuracy_on_bowlist(bow)}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Binary-BoW representation and Multinomial model for News Classification using Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Beginning ...\n",
      "    Estimating class-wise likelihoods of words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfef01b077c843a5bf3017b10f741324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class-wise word likelihood estimation complete!\n",
      "\n",
      "    Estimating class priors ...\n",
      "    Class prior estimation complete!\n",
      "\n",
      "Training Complete!\n",
      "\n",
      "\n",
      "Accuracy on train data: 99.09%\n",
      "\n",
      "Evaluating test data ...\n",
      "\n",
      "Evaluation complete!\n",
      "Accuracy on test data: 82.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bbow_mul = NaiveBayesNewsClassifier(k=0.1, model='multinomial')\n",
    "nb_bbow_mul.train(bbow, vocab, classes, data_dir)\n",
    "\n",
    "nb_bbow_mul.test(test_bbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count-BoW representation and Multinomial model for News Classification using Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Beginning ...\n",
      "    Estimating class-wise likelihoods of words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7210929a1f184cf3ad47e16223f8286a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class-wise word likelihood estimation complete!\n",
      "\n",
      "    Estimating class priors ...\n",
      "    Class prior estimation complete!\n",
      "\n",
      "Training Complete!\n",
      "\n",
      "\n",
      "Accuracy on train data: 98.66%\n",
      "\n",
      "Evaluating test data ...\n",
      "\n",
      "Evaluation complete!\n",
      "Accuracy on test data: 82.78999999999999%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_cbow_mul = NaiveBayesNewsClassifier(k=0.1, model='multinomial')\n",
    "nb_cbow_mul.train(cbow, vocab, classes, data_dir)\n",
    "\n",
    "nb_cbow_mul.test(test_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count-BoW representation and Poisson model for News Classification using Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Beginning ...\n",
      "    Estimating class-wise likelihoods of words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0978348db60a467c8904b57c6e93178b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=584.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=590.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=578.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=593.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=598.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=595.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=593.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=546.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class-wise word likelihood estimation complete!\n",
      "\n",
      "    Estimating class priors ...\n",
      "    Class prior estimation complete!\n",
      "\n",
      "Training Complete!\n",
      "\n",
      "\n",
      "Accuracy on train data: 99.69%\n",
      "\n",
      "Evaluating test data ...\n",
      "\n",
      "Evaluation complete!\n",
      "Accuracy on test data: 83.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_cbow_poi = NaiveBayesNewsClassifier(model='poisson', k=1e-5, alpha = 0.9)\n",
    "nb_cbow_poi.train(cbow, vocab, classes, data_dir)\n",
    "\n",
    "nb_cbow_poi.test(test_cbow)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
